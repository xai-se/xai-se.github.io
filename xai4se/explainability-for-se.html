
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Explainability in Software Engineering &#8212; Explainable AI for Software Engineering</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://xai4se.github.io/xai4se/explainability-for-se.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="A Case Study of Defect Prediction" href="a-case-study-of-defect-prediction.html" />
    <link rel="prev" title="(Step 5) Model Ranking" href="../defect-prediction/model-ranking.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Explainable AI for Software Engineering</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Explainable AI for Software Engineering
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Hands-on Exercise
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/pyexplainer-live-demo.html">
   ASE2021 PyExplainer Live-Demo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/hands-on-exercise.html">
   ASE2021 Hands-on Exercise
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Part1-What is Explainable AI?
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../xai/theory-of-explanations.html">
   A Theory of Explanations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xai/techniques-for-generating-explanations.html">
   Techniques for Generating Explanations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xai/model-specific-techniques.html">
   Model-specific Techniques for Generating Global Explanations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xai/model-agnostic-techniques.html">
   Model-agnostic Techniques for Generating Local Explanations
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Part2-Defect Prediction Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/software-quality-assurance.html">
   Software Quality Assurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/defect-prediction.html">
   Defect Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/data-collection.html">
   (Step 1) Data Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/data-preprocessing.html">
   (Step 2) Data Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/model-construction.html">
   (Step 3) Model Construction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/model-evaluation.html">
   (Step 4) Model Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../defect-prediction/model-ranking.html">
   (Step 5) Model Ranking
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Part3-Explainable AI for Software Engineering
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Explainability in Software Engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="a-case-study-of-defect-prediction.html">
   A Case Study of Defect Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="defective-line-localization.html">
   (Example 1) Help developers localize which lines of code are the most risky
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="local-defect-explanation.html">
   (Example 2) Help developers understand why a file is predicted as defective
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="specific-sq-plan.html">
   (Example 3) Help managers develop software quality improvement plans
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/xai4se/explainability-for-se.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xai4se/xai4se.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xai4se/xai4se.github.io/issues/new?title=Issue%20on%20page%20%2Fxai4se/explainability-for-se.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/xai4se/xai4se.github.io/edit/master/docs/xai4se/explainability-for-se.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/xai4se/xai4se.github.io/master?urlpath=lab/tree/docs/xai4se/explainability-for-se.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/xai4se/xai4se.github.io/blob/master/docs/xai4se/explainability-for-se.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-prevalence-of-ai-in-se">
   The Prevalence of AI in SE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lack-of-explainability-and-trust">
   Lack of Explainability and Trust
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-the-community-moving-to-the-right-direction">
   Is the Community Moving to the Right Direction?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#researchers-focuses">
     Researchers’ Focuses
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#practitioners-needs">
     Practitioners’ Needs
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="explainability-in-software-engineering">
<h1>Explainability in Software Engineering<a class="headerlink" href="#explainability-in-software-engineering" title="Permalink to this headline">¶</a></h1>
<p>Software engineering is by nature a collaborative social practice.
Collaboration among different stakeholders (e.g., users, developers, and
managers) is essential in modern software engineering. As a part of the
collaboration, individuals are often expected to explain decisions made
throughout software development processes to develop appropriate trust
and enable effective communication. Since tool support in software
development processes is an integral part of this collaborative process,
similar expectations are also applied. Such tools should not only
provide insights or generate predictions for recommendation, but also be
able to explain such insights and recommendations.</p>
<div class="section" id="the-prevalence-of-ai-in-se">
<h2>The Prevalence of AI in SE<a class="headerlink" href="#the-prevalence-of-ai-in-se" title="Permalink to this headline">¶</a></h2>
<p>Recent automated and advanced software development tools heavily rely on
Artificial Intelligence and Machine Learning (AI/ML) capabilities to
predict software defects, estimate development effort, and recommend API
choices. However, such AI/ML algorithms are often “black-box”, which
makes it hard for practitioners to understand how the models arrive at a
decision. A lack of explainability of the black-box algorithms leads to
a lack of trust in the predictions or recommendations produced by such
algorithms.</p>
</div>
<div class="section" id="lack-of-explainability-and-trust">
<h2>Lack of Explainability and Trust<a class="headerlink" href="#lack-of-explainability-and-trust" title="Permalink to this headline">¶</a></h2>
<p>While the adoption of software analytics enables software organisations
to distill actionable insights and support decision-making, there are
still many barriers to the successful adoption of such software
analytics in software organizations <span id="id1">[<a class="reference internal" href="../References.html#id53">DTG18</a>]</span>.</p>
<p>First, most software practitioners do not understand the reason behind
the predictions from software analytics systems <span id="id2">[<a class="reference internal" href="../References.html#id53">DTG18</a>]</span>.
They often ask the following questions:</p>
<ul class="simple">
<li><p>Why is this person best suited for this task?</p></li>
<li><p>Why is this file predicted as defective?</p></li>
<li><p>Why is this task required the highest development effort?</p></li>
<li><p>Why should this task be done first?</p></li>
<li><p>Why is this developer predicted to have low productivity?</p></li>
<li><p>How can we improve the quality of software systems in following
iterations?</p></li>
</ul>
<p>These concerns about a lack of explanation often leads to a lack of
trust and transparency, hindering the adoption of software analytics in
practice.</p>
<p>Second, software practitioners are often affected by the decision-making
from software analytics. Our recent work also found that practitioners
are very concerned about their privacy and fairness if defect prediction
models were deployed in practice. Practitioners even asked “Would
developers be laid-off due to the use of defect prediction models for
identifying who are most likely to introduce software
defects?” <span id="id3">[<a class="reference internal" href="../References.html#id127">JTG21</a>]</span>. Article 22 of the European
Union’s General Data Protection Regulation (GDPR) states that the use of
data in decision-making that affects an individual or group requires an
<strong>explanation</strong> for any decision made by an algorithm. Unfortunately,
current software analytics still often do not uphold privacy
laws <span id="id4">[<a class="reference internal" href="../References.html#id126">JTDG20b</a>]</span>. Thus, the risks of unjustified
decision-making of software analytics systems can be catastrophic,
leading to potentially erroneous and costly business
decisions <span id="id5">[<a class="reference internal" href="../References.html#id53">DTG18</a>]</span>.</p>
<div class="figure align-default" id="xai-concept">
<img alt="../_images/xai-concept.png" src="../_images/xai-concept.png" />
<p class="caption"><span class="caption-number">Fig. 8 </span><span class="caption-text">Most software analytics (i.e., defect prediction) studies  have three main goals: (1) predictions; (2) model explanation; and (3) instance explanation. We found that 82% of our study respondents perceived the explanability goal (generating model explanations and instance explanations) is equally useful as the prediction goal. However, we found that 91% (81/96) of defect prediction studies only focus on the prediction goal, and as few as 4% of defect prediction studies focus on the explainability goal.</span><a class="headerlink" href="#xai-concept" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="is-the-community-moving-to-the-right-direction">
<h2>Is the Community Moving to the Right Direction?<a class="headerlink" href="#is-the-community-moving-to-the-right-direction" title="Permalink to this headline">¶</a></h2>
<div class="section" id="researchers-focuses">
<h3>Researchers’ Focuses<a class="headerlink" href="#researchers-focuses" title="Permalink to this headline">¶</a></h3>
<p>We conducted a literature analysis to better understand what researchers
are currently focusing on for defect explanation. We collected 96
primary defect prediction studies that were published in top-tier
Software Engineering venues (i.e., TSE, ICSE, EMSE, FSE, and MSR) during
2015-2020 (as of 11 January 2021). We then characterized the key goals
of each defect prediction study into three main goals: (1) predictions;
(2) model explanation; and (3) instance
explanation <span id="id6">[<a class="reference internal" href="../References.html#id127">JTG21</a>]</span> (see <a class="reference internal" href="#xai-concept"><span class="std std-numref">Fig. 8</span></a>). We found that 91% (81/96) of the defect
prediction studies only focus on making predictions, without considering
explaining the predictions. As few as 4% of the defect prediction
studies focus on explaining the predictions of defect prediction models. This indicates that the explainability and
actionability of software analytics is still very under researched.</p>
</div>
<div class="section" id="practitioners-needs">
<h3>Practitioners’ Needs<a class="headerlink" href="#practitioners-needs" title="Permalink to this headline">¶</a></h3>
<p>We conducted a qualitative survey to better understand what
practitioners perceive as the usefulness of each goal of defect
prediction models. We found that practitioners perceive that the
explainability and actionability of software analytics are as <strong>equally
useful</strong> as the predictions <span id="id7">[<a class="reference internal" href="../References.html#id127">JTG21</a>]</span>. 82% of our
respondents said that the explanability goal (generating model
explanations and instance explanations) is as useful as the prediction
goal (see <a class="reference internal" href="#xai-concept"><span class="std std-numref">Fig. 8</span></a>). Thus, we argue that <strong>explainable and actionable software
analytics is urgently and critically needed</strong>. The research and practice
communities should thus start answering the key question: <em>“How can we
make software analytics more explainable and actionable?”</em>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parts of this chapter have been published by Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, John Grundy: Actionable Analytics: Stop Telling Me What It Is; Please Tell Me What To Do. IEEE Software 38.4 (2021)”</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "xaitools"
        },
        kernelOptions: {
            kernelName: "xaitools",
            path: "./xai4se"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'xaitools'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../defect-prediction/model-ranking.html" title="previous page">(Step 5) Model Ranking</a>
    <a class='right-next' id="next-link" href="a-case-study-of-defect-prediction.html" title="next page">A Case Study of Defect Prediction</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chakkrit Tantithamthavorn and Jirayus Jiarpakdee<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            <script>mermaid.init();</script> <div class="row_footer"> This project has received funding from the <a href="https://www.arc.gov.au/">Australian Research Council</a>'s Discovery Early Career Researcher Award (ARC DECRA) funding scheme (DE200100941). This book reflects the views of the authors and neither Australian Research Council nor Monash University are liable for any use that may be made of the information contained herein. The content of this project is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. The source code that is part of the content, as well as the source code used to format and display that content is licensed under the MIT License. </div>
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-54962993-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>